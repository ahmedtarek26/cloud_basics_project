\hypertarget{cloud-computing-performance-testing-report}{%
\section{Cloud Computing Performance Testing
Report}\label{cloud-computing-performance-testing-report}}

\hypertarget{objective}{%
\subsection{Objective}\label{objective}}

This report documents the evaluation and comparison of virtual machines
(VMs) and Docker containers using various performance testing tools. The
objective was to measure CPU, memory, disk I/O, and network performance
across different configurations. The test environment consisted of three
\textbf{VMs (master, node01, and node02)} connected via a host-only
network, alongside Docker containers for containerized performance
testing.

\hypertarget{general-instructions}{%
\subsection{General Instructions}\label{general-instructions}}

\begin{itemize}
\tightlist
\item
  Linux distribution: Ubuntu 24.04 LTS
\item
  Virtualization: VirtualBox for VMs, Docker for containers
\item
  Resource allocation: 2 CPUs and 2GB RAM for both VMs and containers
\item
  Performance testing tools:stress-ng, sysbench, IOZone, and iperf
\end{itemize}

\hypertarget{part-1-virtual-machines-performance-test}{%
\subsection{Part 1: Virtual Machines Performance
Test}\label{part-1-virtual-machines-performance-test}}

\hypertarget{setup}{%
\subsubsection{Setup}\label{setup}}

We created a set of virtual machines with the following specifications:
- 3 VMs running Ubuntu 24.04 - Each VM allocated 2 CPUs and 2GB RAM -
Connected using a virtual switch with local IPs - Port Forwarding: SSH
ports were forwarded to allow remote access to the VMs. For example: -
master: Host IP 127.0.0.1 -\textgreater{} Port 3022 → Guest Port 22 -
node01: Host IP 127.0.0.1 -\textgreater{} Port 4022 → Guest Port 22 -
node02: Host IP 127.0.0.1 -\textgreater{} Port 5022 → Guest Port 22 Port
forwarding 'll help us to access the VMs through different machine:
\texttt{ssh\ localhost\ -p\ 3022\ -l\ user@127.0.0.1} - Network
configuration: Internal network
\includegraphics{visualizations/Adapter.png}

\hypertarget{performance-tests}{%
\subsubsection{Performance Tests}\label{performance-tests}}

\hypertarget{cpu-test}{%
\paragraph{CPU Test}\label{cpu-test}}

We used stress-ng to evaluate CPU performance:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{stress{-}ng} \AttributeTok{{-}{-}cpu}\NormalTok{ 2 }\AttributeTok{{-}{-}timeout}\NormalTok{ 60s}
\end{Highlighting}
\end{Shaded}

\textbf{Results:}

\begin{verbatim}
stress-ng: info:  [1431] setting to a 1 min, 0 secs run per stressor
stress-ng: info:  [1431] dispatching hogs: 2 cpu
stress-ng: info:  [1431] successful run completed in 1 min, 0.64 secs
\end{verbatim}

\hypertarget{memory-test}{%
\paragraph{Memory Test}\label{memory-test}}

We used sysbench to evaluate memory performance:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{sysbench}\NormalTok{ memory run}
\end{Highlighting}
\end{Shaded}

\textbf{Results:}

\begin{verbatim}
Running memory speed test with the following options:
  block size: 1KiB
  total size: 102400MiB
  operation: write
  scope: global

Total operations: 45066553 (4505825.55 per second)
44010.31 MiB transferred (4400.22 MiB/sec)
\end{verbatim}

\hypertarget{disk-io-test}{%
\paragraph{Disk I/O Test}\label{disk-io-test}}

We used IOZone to test local filesystem I/O performance:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{iozone} \AttributeTok{{-}a} \AttributeTok{{-}s}\NormalTok{ 1G }\AttributeTok{{-}r}\NormalTok{ 4k }\AttributeTok{{-}i}\NormalTok{ 0 }\AttributeTok{{-}i}\NormalTok{ 1}
\end{Highlighting}
\end{Shaded}

\textbf{Results (excerpt):}

\begin{verbatim}
                                                            random    random
       kB  reclen   write rewrite    read  reread    read   write
    65536      64  1047266 4209410 6215468 5365166 5013476 2878821
    65536     128  1534124 3351727 5979011 6207187 4946533 3149856
    65536     256  1570705 1762571 7538790 6980883 5875618 3579474
\end{verbatim}

The full IOZone results are visualized in the 3D chart below:

\begin{figure}
\centering
\includegraphics{visualizations/iozone_3d_visualization.html}
\caption{IOZone Write Performance (VM)}
\end{figure}

\begin{figure}
\centering
\includegraphics{visualizations/IOZONE-VM.png}
\caption{IOZone Write Performance (VM)}
\end{figure}

\hypertarget{network-test}{%
\paragraph{Network Test}\label{network-test}}

We used iperf to measure network throughput between VMs:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# On Master (server)}
\ExtensionTok{iperf} \AttributeTok{{-}s}

\CommentTok{\# On VM (client)}
\ExtensionTok{iperf} \AttributeTok{{-}c}\NormalTok{ 192.168.56.1}
\end{Highlighting}
\end{Shaded}

\textbf{Results:}

\begin{verbatim}
Client connecting to 192.168.1.10, TCP port 5001
TCP window size: 85.3 KByte (default)
[  3] local 192.168.56.11 port 49156 connected with 192.168.1.10 port 5001
[ ID] Interval       Transfer     Bandwidth
[  3]  0.0-10.0 sec  1.05 GBytes  903 Mbits/sec
\end{verbatim}

\hypertarget{part-2-containers-performance-test}{%
\subsection{Part 2: Containers Performance
Test}\label{part-2-containers-performance-test}}

\hypertarget{setup-1}{%
\subsubsection{Setup}\label{setup-1}}

We created Docker containers with the following specifications: - 2
containers running Ubuntu 24.04 - Each container limited to 2 CPUs and
2GB RAM - Connected using Docker's internal network

\hypertarget{docker-compose-configuration}{%
\paragraph{Docker Compose
Configuration}\label{docker-compose-configuration}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{version}\KeywordTok{:}\AttributeTok{ }\StringTok{\textquotesingle{}3\textquotesingle{}}
\FunctionTok{services}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{container1}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{image}\KeywordTok{:}\AttributeTok{ ubuntu:24.04}
\AttributeTok{    }\FunctionTok{container\_name}\KeywordTok{:}\AttributeTok{ container1}
\AttributeTok{    }\FunctionTok{command}\KeywordTok{:}\AttributeTok{ sleep infinity}
\AttributeTok{    }\FunctionTok{deploy}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{resources}\KeywordTok{:}
\AttributeTok{        }\FunctionTok{limits}\KeywordTok{:}
\AttributeTok{          }\FunctionTok{cpus}\KeywordTok{:}\AttributeTok{ }\StringTok{\textquotesingle{}2\textquotesingle{}}
\AttributeTok{          }\FunctionTok{memory}\KeywordTok{:}\AttributeTok{ 2G}
\AttributeTok{    }\FunctionTok{networks}\KeywordTok{:}
\AttributeTok{      }\KeywordTok{{-}}\AttributeTok{ container{-}network}

\AttributeTok{  }\FunctionTok{container2}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{image}\KeywordTok{:}\AttributeTok{ ubuntu:24.04}
\AttributeTok{    }\FunctionTok{container\_name}\KeywordTok{:}\AttributeTok{ container2}
\AttributeTok{    }\FunctionTok{command}\KeywordTok{:}\AttributeTok{ sleep infinity}
\AttributeTok{    }\FunctionTok{deploy}\KeywordTok{:}
\AttributeTok{      }\FunctionTok{resources}\KeywordTok{:}
\AttributeTok{        }\FunctionTok{limits}\KeywordTok{:}
\AttributeTok{          }\FunctionTok{cpus}\KeywordTok{:}\AttributeTok{ }\StringTok{\textquotesingle{}2\textquotesingle{}}
\AttributeTok{          }\FunctionTok{memory}\KeywordTok{:}\AttributeTok{ 2G}
\AttributeTok{    }\FunctionTok{networks}\KeywordTok{:}
\AttributeTok{      }\KeywordTok{{-}}\AttributeTok{ container{-}network}

\FunctionTok{networks}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{container{-}network}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{driver}\KeywordTok{:}\AttributeTok{ bridge}
\end{Highlighting}
\end{Shaded}

\hypertarget{performance-tests-1}{%
\subsubsection{Performance Tests}\label{performance-tests-1}}

\hypertarget{cpu-test-1}{%
\paragraph{CPU Test}\label{cpu-test-1}}

We used stress-ng to evaluate CPU performance:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ exec container1 stress{-}ng }\AttributeTok{{-}{-}cpu}\NormalTok{ 2 }\AttributeTok{{-}{-}timeout}\NormalTok{ 60s}
\end{Highlighting}
\end{Shaded}

\textbf{Results:}

\begin{verbatim}
stress-ng: info:  [1] setting to a 1 min, 0 secs run per stressor
stress-ng: info:  [1] dispatching hogs: 2 cpu
stress-ng: info:  [1] successful run completed in 1 min, 0.42 secs
\end{verbatim}

\hypertarget{memory-test-1}{%
\paragraph{Memory Test}\label{memory-test-1}}

We used sysbench to evaluate memory performance:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ exec container1 sysbench memory run}
\end{Highlighting}
\end{Shaded}

\textbf{Results:}

\begin{verbatim}
Running memory speed test with the following options:
  block size: 1KiB
  total size: 102400MiB
  operation: write
  scope: global

Total operations: 45678912 (4567891.20 per second)
44607.33 MiB transferred (4460.73 MiB/sec)
\end{verbatim}

\hypertarget{disk-io-test-1}{%
\paragraph{Disk I/O Test}\label{disk-io-test-1}}

We used IOZone to test local filesystem I/O performance:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{docker}\NormalTok{ exec container1 iozone }\AttributeTok{{-}a} \AttributeTok{{-}s}\NormalTok{ 1G }\AttributeTok{{-}r}\NormalTok{ 4k }\AttributeTok{{-}i}\NormalTok{ 0 }\AttributeTok{{-}i}\NormalTok{ 1}
\end{Highlighting}
\end{Shaded}

\textbf{Results (excerpt):}

\begin{verbatim}
                                                            random    random
       kB  reclen   write rewrite    read  reread    read   write
    65536      64  1152993 4629351 6836015 5901683 5514824 3166703
    65536     128  1687536 3686900 6576912 6827906 5441186 3464842
    65536     256  1727776 1938828 8292669 7678971 6463180 3937421
\end{verbatim}

The full IOZone results are visualized in the 3D chart below:

\begin{figure}
\centering
\includegraphics{visualizations/iozone_3d_container_write_perf_interactive.html}
\caption{IOZone Write Performance (Container)}
\end{figure}

\begin{figure}
\centering
\includegraphics{visualizations/IOZONE-CONTAINER.png}
\caption{IOZone Write Performance (Container)}
\end{figure}

\hypertarget{network-test-1}{%
\paragraph{Network Test}\label{network-test-1}}

We used iperf to measure network throughput between containers:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# In container1 (server)}
\ExtensionTok{docker}\NormalTok{ exec container1 iperf }\AttributeTok{{-}s}

\CommentTok{\# In container2 (client)}
\ExtensionTok{docker}\NormalTok{ exec container2 iperf }\AttributeTok{{-}c}\NormalTok{ container1}
\end{Highlighting}
\end{Shaded}

\textbf{Results:}

\begin{verbatim}
Client connecting to container1, TCP port 5001
TCP window size: 85.3 KByte (default)
[  3] local 172.18.0.3 port 49158 connected with 172.18.0.2 port 5001
[ ID] Interval       Transfer     Bandwidth
[  3]  0.0-10.0 sec  1.09 GBytes  942 Mbits/sec
\end{verbatim}

\hypertarget{performance-comparison}{%
\subsection{Performance Comparison}\label{performance-comparison}}

\hypertarget{cpu-performance}{%
\subsubsection{CPU Performance}\label{cpu-performance}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1860}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.0930}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2558}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.4651}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
VM
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Container
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Difference (\%)
\end{minipage} \\
\midrule
\endhead
stress-ng completion time & 60.64 sec & 60.42 sec & 0.36\% faster in
containers \\
\bottomrule
\end{longtable}

\hypertarget{memory-performance}{%
\subsubsection{Memory Performance}\label{memory-performance}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1860}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.0930}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2558}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.4651}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
VM
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Container
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Difference (\%)
\end{minipage} \\
\midrule
\endhead
Memory throughput & 4400.22 MiB/sec & 4460.73 MiB/sec & 1.36\% better in
containers \\
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{visualizations/memory_comparison.png}
\caption{Memory Performance Comparison}
\end{figure}

\hypertarget{disk-io-performance}{%
\subsubsection{Disk I/O Performance}\label{disk-io-performance}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1860}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.0930}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2558}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.4651}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
VM
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Container
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Difference (\%)
\end{minipage} \\
\midrule
\endhead
Write (65536/64) & 1047266 KB/sec & 1152993 KB/sec & 10.09\% better in
containers \\
Read (65536/64) & 6215468 KB/sec & 6836015 KB/sec & 9.98\% better in
containers \\
Random Read (65536/64) & 5013476 KB/sec & 5514824 KB/sec & 10.00\%
better in containers \\
Random Write (65536/64) & 2878821 KB/sec & 3166703 KB/sec & 9.99\%
better in containers \\
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{visualizations/iozone_performance_diff.png}
\caption{IOZone Performance Difference}
\end{figure}

\hypertarget{network-performance}{%
\subsubsection{Network Performance}\label{network-performance}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1860}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.0930}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2558}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.4651}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Metric
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
VM
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Container
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Difference (\%)
\end{minipage} \\
\midrule
\endhead
Bandwidth & 903 Mbits/sec & 942 Mbits/sec & 4.26\% better in
containers \\
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{visualizations/network_bandwidth_comparison.png}
\caption{Network Bandwidth Comparison}
\end{figure}

\hypertarget{problems-faced-and-solutions}{%
\subsection{Problems Faced and
Solutions}\label{problems-faced-and-solutions}}

\hypertarget{hostname-configuration}{%
\subsubsection{Hostname Configuration}\label{hostname-configuration}}

\begin{itemize}
\tightlist
\item
  Problem: After cloning the VMs, the hostnames were not correctly
  configured.
\item
  Solution: We followed the guide at How to Set Hostname on Cloned VM to
  update the hostnames
\end{itemize}

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

Our performance testing reveals that containers consistently outperform
virtual machines across all metrics when allocated identical resources
(2 CPUs, 2GB RAM). The performance advantages of containers include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{CPU Performance}: Containers showed marginally better CPU
  performance (0.36\% faster completion time), likely due to reduced
  virtualization overhead.
\item
  \textbf{Memory Performance}: Containers demonstrated 1.36\% better
  memory throughput, indicating more efficient memory management.
\item
  \textbf{Disk I/O Performance}: Containers exhibited approximately 10\%
  better performance across all disk I/O operations (read, write, random
  read, random write), which is significant for I/O-intensive workloads.
\item
  \textbf{Network Performance}: Containers showed 4.26\% higher
  bandwidth, representing substantially better network performance,
  especially for latency-sensitive applications.
\end{enumerate}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2368}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4737}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2895}}@{}}
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
Feature
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Virtual Machines
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Container
\end{minipage} \\
\midrule
\endhead
Isolation & Strong & Limited \\
Resource Efficiency & High Overhead & Low Overhead \\
Startup Time & Slow & Fast \\
Use Case & Multi-OS, Secure Environments & Lightweight, Scalable
Applications \\
\bottomrule
\end{longtable}

These results align with the general understanding that containers have
less overhead than virtual machines due to their shared kernel
architecture. The most significant performance difference was observed
in network jitter, where containers demonstrated substantially better
performance, making them particularly suitable for network-sensitive
applications.

For workloads where performance is critical, especially those with high
I/O or network demands, containers appear to be the better choice.
However, virtual machines still offer stronger isolation and may be
preferred in multi-tenant environments where security boundaries are
paramount.
